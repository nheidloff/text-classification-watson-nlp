<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"><channel><title>Niklas Heidloff</title><atom:link href="http://heidloff.net/feed/" rel="self" type="application/rss+xml"/><link>http://heidloff.net</link><description/><lastBuildDate>
	Thu, 24 Nov 2022 10:47:53 +0000	</lastBuildDate><language>en-US</language><sy:updatePeriod>
	hourly	</sy:updatePeriod><sy:updateFrequency>
	1	</sy:updateFrequency><generator>https://wordpress.org/?v=5.1.15</generator><site xmlns="com-wordpress:feed-additions:1">102773794</site><item><title>Building custom IBM Watson NLP Images</title><link>http://heidloff.net/article/building-custom-ibm-watson-nlp-images-models/</link><pubDate>Wed, 23 Nov 2022 13:45:24 +0000</pubDate><dc:creator><![CDATA[Niklas Heidloff]]></dc:creator><category><![CDATA[Articles]]></category><guid isPermaLink="false">http://heidloff.net/?p=5378</guid><description><![CDATA[<p>IBM Watson NLP (Natural Language Understanding) and Watson Speech containers can be run locally, on-premises or Kubernetes and OpenShift clusters. Via REST and gRCP APIs AI can easily be embedded in applications. This post describes how to package custom models in container images for deployments. To set some context, check out the landing page IBM [&#8230;]</p>
<p>The post <a rel="nofollow" href="http://heidloff.net/article/building-custom-ibm-watson-nlp-images-models/">Building custom IBM Watson NLP Images</a> appeared first on <a rel="nofollow" href="http://heidloff.net">Niklas Heidloff</a>.</p>
]]></description><content:encoded><![CDATA[<p><em>IBM Watson NLP (Natural Language Understanding) and Watson Speech containers can be run locally, on-premises or Kubernetes and OpenShift clusters. Via REST and gRCP APIs AI can easily be embedded in applications. This post describes how to package custom models in container images for deployments.</em><span id="more-5378"></span></p>
<p>To set some context, check out the landing page <a href="https://www.ibm.com/products/ibm-watson-natural-language-processing" rel="noopener noreferrer" target="_blank">IBM Watson NLP Library for Embed</a>. The Watson NLP containers can be run on different container platforms, they provide REST and gRCP interfaces, they can be extended with custom models and they can easily be embedded in solutions. While this offering is new, the underlaying functionality has been used and optimized for a long time in IBM offerings like the IBM Watson Assistant and NLU (Natural Language Understanding) SaaS services and IBM Cloud Pak for Data.</p>
<p>To try it, a <a href="https://www.ibm.com/account/reg/us-en/signup?formid=urx-51726" rel="noopener noreferrer" target="_blank">trial</a> is available. The container images are stored in an IBM container registry that is accessed via an <a href="https://www.ibm.com/account/reg/signup?formid=urx-51726" rel="noopener noreferrer" target="_blank">IBM Entitlement Key</a>.</p>
<p><strong>Downloading trained Models</strong></p>
<p>My post <a href="http://heidloff.net/article/training-ibm-watson-nlp-models/" rel="noopener noreferrer" target="_blank">Training IBM Watson NLP Models</a> explains how to train Watson NLP based models with notebooks in Watson Studio. After the training models can be saved as file asset in the Watson Studio project and they can be downloaded.</p>
<pre class="brush: plain; title: ; notranslate">
project.save_data('ensemble_model', data=ensemble_model.as_file_like_object(), overwrite=True)
</pre>
<p><img src="http://heidloff.net/wp-content/uploads/2022/11/Screenshot-2022-11-17-at-14.35.05.png" alt="" width="1910" height="858" class="alignnone size-full wp-image-5379" style="border: 1px solid #ddd;" srcset="http://heidloff.net/wp-content/uploads/2022/11/Screenshot-2022-11-17-at-14.35.05.png 1910w, http://heidloff.net/wp-content/uploads/2022/11/Screenshot-2022-11-17-at-14.35.05-300x135.png 300w, http://heidloff.net/wp-content/uploads/2022/11/Screenshot-2022-11-17-at-14.35.05-768x345.png 768w, http://heidloff.net/wp-content/uploads/2022/11/Screenshot-2022-11-17-at-14.35.05-1024x460.png 1024w" sizes="(max-width: 1910px) 100vw, 1910px" /></p>
<p>The models are typically stored locally a directory &#8216;models&#8217;. The directory can contain the zipped file with or without &#8216;.zip&#8217; extension. The zip file can also be extracted. The name of the file (or directory name when extracted) is the model id which you&#8217;ll need later to refer to it.</p>
<p>There are three ways to build deploy Watson NLP and models.</p>
<ol>
<li>Standalone containers: One pod with one container including the NLP runtime and the models</li>
<li>Init containers for models: One pod with one NLP runtime container and one init container per model</li>
<li>Cloud object storage for models and kServe (not covered in this post)</li>
</ol>
<p><strong>Building Standalone Images with custom Models</strong></p>
<p>The easiest way is to put everything in one image.</p>
<pre class="brush: plain; title: ; notranslate">
$ docker login cp.icr.io --username cp --password &lt;entitlement_key&gt; 
</pre>
<p>The following Dockerfile extends the runtime image with a local copy of the model(s).</p>
<pre class="brush: plain; title: ; notranslate">
ARG WATSON_RUNTIME_BASE=&quot;cp.icr.io/cp/ai/watson-nlp-runtime:1.0.18&quot;
FROM ${WATSON_RUNTIME_BASE} as base
ENV LOCAL_MODELS_DIR=/app/models
ENV ACCEPT_LICENSE=true
COPY models /app/models
</pre>
<p>The following commands build the image and run the container.</p>
<pre class="brush: plain; title: ; notranslate">
$ docker build . -t watson-nlp-custom-container:v1
$ docker run -d -e ACCEPT_LICENSE=true -p 8085:8085 watson-nlp-custom-container:v1
</pre>
<p><strong>Building Standalone Images with predefined Models</strong></p>
<p>Similarly to custom models, predefined models can be put in a standalone image. Predefined Watson NLP models are available in the IBM image registry as init container images. When these containers are run normally, they will invoke an unpack_model.sh script. The following Dockerfile shows how to download the images with models and how to put the models into the directory where the runtime container expects them.</p>
<pre class="brush: plain; title: ; notranslate">
ARG WATSON_RUNTIME_BASE=&quot;cp.icr.io/cp/ai/watson-nlp-runtime:1.0.18&quot;
ARG SENTIMENT_MODEL=&quot;cp.icr.io/cp/ai/watson-nlp_sentiment_aggregated-cnn-workflow_lang_en_stock:1.0.6&quot;
ARG EMOTION_MODEL=&quot;cp.icr.io/cp/ai/watson-nlp_classification_ensemble-workflow_lang_en_tone-stock:1.0.6&quot;

FROM ${SENTIMENT_MODEL} as model1
RUN ./unpack_model.sh

FROM ${EMOTION_MODEL} as model2
RUN ./unpack_model.sh

FROM ${WATSON_RUNTIME_BASE} as release

RUN true &amp;&amp; \
    mkdir -p /app/models

ENV LOCAL_MODELS_DIR=/app/models
COPY --from=model1 app/models /app/models
COPY --from=model2 app/models /app/models
</pre>
<p><strong>Building Model Images for Init Containers</strong></p>
<p>Custom models can also be put in init container images. A Python tool is provided to do this.</p>
<pre class="brush: plain; title: ; notranslate">
$ python3 -m venv client-env
$ source client-env/bin/activate
$ pip install watson-embed-model-packager
$ python3 -m watson_embed_model_packager setup --library-version watson_nlp:3.2.0 --local-model-dir models --output-csv ./customer-complaints.csv
$ python3 -m watson_embed_model_packager build --config customer-complaints.csv
$ docker tag watson-nlp_ensemble_model:v1 &lt;REGISTRY&gt;/&lt;NAMESPACE&gt;/watson-nlp_ensemble_model:v1
$ docker push &lt;REGISTRY&gt;/&lt;NAMESPACE&gt;/watson-nlp_ensemble_model:v1
</pre>
<p>To find out more about Watson NLP and Watson for Embed in general, check out these resources:</p>
<ul>
<li><a href="https://www.ibm.com/docs/en/watson-libraries?topic=watson-natural-language-processing-library-embed-home" rel="noopener noreferrer" target="_blank">IBM Watson NLP Documentation</a></li>
<li><a href="https://www.ibm.com/docs/en/watson-libraries?topic=models-catalog" rel="noopener noreferrer" target="_blank">IBM Watson NLP Model catalog</a></li>
<li><a href="https://www.ibm.com/account/reg/us-en/signup?formid=urx-51726" rel="noopener noreferrer" target="_blank">IBM Watson NLP Trial</a></li>
<li><a href="https://www.ibm.com/account/reg/us-en/subscribe?formid=urx-51726" rel="noopener noreferrer" target="_blank">IBM Watson NLP Entitlement Key</a></li>
<li><a href="https://github.com/IBM/watson-automation" rel="noopener noreferrer" target="_blank">Automation for Watson NLP Deployments</a></li>
<li><a href="http://heidloff.net/article/running-ibm-watson-nlp-locally-in-containers/" rel="noopener noreferrer" target="_blank">Running IBM Watson NLP locally in Containers</a></li>
<li><a href="http://heidloff.net/article/running-ibm-watson-nlp-in-minikube/" rel="noopener noreferrer" target="_blank">Running IBM Watson NLP in Minikube</a></li>
</ul>
<p>The post <a rel="nofollow" href="http://heidloff.net/article/building-custom-ibm-watson-nlp-images-models/">Building custom IBM Watson NLP Images</a> appeared first on <a rel="nofollow" href="http://heidloff.net">Niklas Heidloff</a>.</p>
]]></content:encoded><post-id xmlns="com-wordpress:feed-additions:1">5378</post-id></item></channel></rss>