page2-elem1,Running IBM Watson NLP in Minikube.
page2-elem1,IBM Watson NLP (Natural Language Understanding) and Watson Speech containers can be run locally on-premises or Kubernetes and OpenShift clusters.
page2-elem1,Via REST and gRCP APIs AI can easily be embedded in applications.
page2-elem1,This post describes how to run Watson NLP locally in Minikube.
page2-elem1,To set some context check out the landing page IBM Watson NLP Library for Embed [https://www.ibm.com/products/ibm-watson-natural-language-processing].
page2-elem1,The Watson NLP containers can be run on different container platforms they provide REST and gRCP interfaces they can be extended with custom models and they can easily be embedded in solutions.
page2-elem1,To try it a trial [https://www.ibm.com/account/reg/us-en/signup?formid=urx-51726] is available.
page2-elem1,The container images are stored in an IBM container registry that is accessed via an IBM Entitlement Key [https://www.ibm.com/account/reg/signup?formid=urx-51726].
page2-elem1,How to run NLP locally in Minikube
page2-elem1,My post Running IBM Watson NLP locally in Containers [http://heidloff.net/article/running-ibm-watson-nlp-locally-in-containers/] explained how to run Watson NLP locally in Docker.
page2-elem1,The instructions below describe how to deploy Watson NLP locally to Minikube via the Watson NLP Helm chart [https://github.com/IBM/watson-automation/blob/90e61e05a5d0eacd268c97fc3c8b67e285c99241/documentation/NLPHelmChart.md].
page2-elem1,First you need to install Minikube for example via brew on MacOS.
page2-elem1,Next Minikube needs to be started with more memory and disk size than the Minikube defaults.
page2-elem1,I’ve used the settings below which is more than required but I wanted to leave space for other applications.
page2-elem1,Note that you also need to give your container runtime more resources.
page2-elem1,For example if you use Docker Desktop go to Preferences-Resources and define your settings.
page2-elem1,$ brew install minikube
page2-elem1,$ minikube start --cpus 12 --memory 16000 --disk-size 50g
page2-elem1,For some reason in my setup the watson-nlp-runtime image couldn’t be pulled by the Deployment resource/operator.
page2-elem1,I guess it’s related to the big size of the image.
page2-elem1,I’ve found this workaround:
page2-elem1,$ eval $(minikube docker-env)
page2-elem1,$ docker login cp.icr.io --username cp --password <entitlement_key>
page2-elem1,$ docker pull cp.icr.io/cp/ai/watson-nlp-runtime:1.0.18
page2-elem1,Next the namespace and secret need to be created.
page2-elem1,$ kubectl create namespace watson-demo
page2-elem1,$ kubectl config set-context --current --namespace=watson-demo
page2-elem1,$ kubectl create secret docker-registry \
page2-elem1,--docker-server=cp.icr.io \
page2-elem1,--docker-username=cp \
page2-elem1,--docker-password=<your IBM Entitlement Key> \
page2-elem1,-n watson-demo \
page2-elem1,ibm-entitlement-key
page2-elem1,After this a repo with the Helm chart and another repo with a sample values.yaml [https://github.com/IBM/watson-automation/blob/94f28f12a58608f7b7fe355d36f101ddf7cd8cb8/helm-nlp/values.yaml] file are cloned and the license needs to be accepted.
page2-elem1,$ git clone https://github.com/cloud-native-toolkit/terraform-gitops-watson-nlp
page2-elem1,$ git clone https://github.com/IBM/watson-automation.git
page2-elem1,$ code watson-automation/helm-nlp/values.yaml #change acceptLicense to true
page2-elem1,$ cp watson-automation/helm-nlp/values.yaml terraform-gitops-watson-nlp/chart/watson-nlp/values.yaml
page2-elem1,componentName: watson-nlp
page2-elem1,acceptLicense: true
page2-elem1,serviceType: ClusterIP
page2-elem1,imagePullSecrets:
page2-elem1,- ibm-entitlement-key
page2-elem1,registries:
page2-elem1,- name: watson
page2-elem1,url: cp.icr.io/cp/ai
page2-elem1,runtime:
page2-elem1,registry: watson
page2-elem1,image: watson-nlp-runtime:1.0.18
page2-elem1,models:
page2-elem1,- registry: watson
page2-elem1,image: watson-nlp_syntax_izumo_lang_en_stock:1.0.7
page2-elem1,Finally the chart can be installed.
page2-elem1,$ cd terraform-gitops-watson-nlp/chart/watson-nlp
page2-elem1,$ helm install -f values.yaml watson-embedded .
page2-elem1,$ kubectl get pods -n watson-demo --watch
page2-elem1,$ kubectl get deployment/watson-embedded-watson-nlp -n watson-demo
page2-elem1,$ kubectl get svc/watson-embedded-watson-nlp -n watson-demo
page2-elem1,When you open the Kubernetes Dashboard (via ‘minikube dashboard’) you’ll see the deployed resources.
page2-elem1,The Watson NLP pod contains the watson-nlp-runtime container and a simple syntax model container.
page2-elem1,To invoke Watson NLP via REST you need to find out the IP address and port.
page2-elem1,Alternatively you could use port forwarding.
page2-elem1,$ minikube service watson-embedded-watson-nlp -n watson-demo --url
page2-elem1,$ curl -X POST "http://<ip-and-port>/v1/watson.runtime.nlp.v1/NlpService/SyntaxPredict" \
page2-elem1,-H "accept: application/json" \
page2-elem1,-H "grpc-metadata-mm-model-id: syntax_izumo_lang_en_stock" \
page2-elem1,-H "content-type: application/json" \
page2-elem1,-d " { \"rawDocument\": { \"text\": \"It is so easy to embed Watson NLP in applications.
page2-elem1,Very cool.\" }}"
page2-elem1,The NLP containers also provides a gRCP interface [https://github.com/IBM/watson-automation#grpc].
page2-elem1,To find out more about Watson NLP check out these resources:
page2-elem1,* Documentation [https://www.ibm.com/docs/en/watson-libraries?topic=watson-natural-language-processing-library-embed-home]
page2-elem1,* Model catalog [https://www.ibm.com/docs/en/watson-libraries?topic=models-catalog]
page2-elem1,* Trial [https://www.ibm.com/products/ibm-watson-natural-language-processing]
page2-elem1,* Entitlement key [https://www.ibm.com/account/reg/us-en/subscribe?formid=urx-51726]
page2-elem1,* Automation for Watson NLP Deployments [https://github.com/IBM/watson-automation]
page2-elem1,* Running IBM Watson NLP locally in Containers [http://heidloff.net/article/running-ibm-watson-nlp-locally-in-containers/]
page2-elem1,* Running IBM Watson Speech to Text in Containers [http://heidloff.net/article/running-ibm-watson-speech-to-text-in-containers/]
page2-elem1,* Running IBM Watson Text to Speech in Containers [http://heidloff.net/article/running-ibm-watson-text-to-speech-in-containers/]
page2-elem1,The post Running IBM Watson NLP in Minikube [http://heidloff.net/article/running-ibm-watson-nlp-in-minikube/] appeared first on Niklas Heidloff [http://heidloff.net].